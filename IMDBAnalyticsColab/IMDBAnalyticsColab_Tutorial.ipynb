{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdmartinev/IMDBAnalytics/blob/main/IMDBAnalyticsColab/IMDBAnalyticsColab_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaoFwkr4n_eF"
      },
      "source": [
        "# Tutorial\n",
        "\n",
        "En este tutorial, analizará una base de datos de películas *IMDb Movies dataset* para aprender conceptos y procedimientos básicos utilizados en el análisis de datos. Al final, usted tendrá la capacidad de:\n",
        "\n",
        "-  Importar y explorar datos\n",
        "-  Realizar limpieza de datos\n",
        "-  Utilizar Pandas/Plotly para crear histogramas que le permitan analizar la distribución de los datos\n",
        "-  Crear gráficos de líneas y de barras (_line charts_ & _bar charts_) para visualizar datos\n",
        "-  Utilizar Pandas y Plotly para crear gráficas de dispersión (_scatter plots_) para realizar análisis de correlación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hzf1d7JpfrX"
      },
      "source": [
        "## Descarga de datos\n",
        "\n",
        "Lo primero que hará será descargar los datos con los que va a trabajar:\n",
        "\n",
        "- Tabla de películas (archivo csv).\n",
        "- _Shapefile_ (archivo .shp y archivos auxiliares) con la información necesaria para graficar mapas. De forma resumida, este archivo almacena información geométrica en forma de líneas o polígonos. En este caso partícular, el _shapefile_ tendrá la geometría de los países que nos servirá para pintar en el mapa datos relevantes extraídos de la información contenida en la base de datos de películas.  \n",
        "\n",
        "Estos archivos quedarán en la carpeta _/content/IMDBAnalyticsData/_ asociada con el sistema operativo del servidor en el que se está ejecutando google colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TeLGFIUQsOdZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-02 15:27:13--  https://docs.google.com/uc?export=download&id=1osH_xhTCW4Qh7f00VU_UaRK5whEXe8dr\n",
            "Cargado certificado CA '/etc/ssl/certs/ca-certificates.crt'\n",
            "Resolviendo docs.google.com (docs.google.com)... 142.250.78.78, 2800:3f0:4005:409::200e\n",
            "Conectando con docs.google.com (docs.google.com)[142.250.78.78]:443... conectado.\n",
            "Petición HTTP enviada, esperando respuesta... 303 See Other\n",
            "Localización: https://doc-14-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c2e5j4bk6mhve2vvs3g0o6k4q81trj85/1677806700000/15315348669826032119/*/1osH_xhTCW4Qh7f00VU_UaRK5whEXe8dr?e=download&uuid=6e7f63af-d22e-48ba-84d4-e7991549feb6 [siguiendo]\n",
            "Aviso: no se admiten comodines en HTTP.\n",
            "--2023-03-02 15:27:14--  https://doc-14-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/c2e5j4bk6mhve2vvs3g0o6k4q81trj85/1677806700000/15315348669826032119/*/1osH_xhTCW4Qh7f00VU_UaRK5whEXe8dr?e=download&uuid=6e7f63af-d22e-48ba-84d4-e7991549feb6\n",
            "Resolviendo doc-14-6c-docs.googleusercontent.com (doc-14-6c-docs.googleusercontent.com)... 172.217.30.193, 2800:3f0:4005:401::2001\n",
            "Conectando con doc-14-6c-docs.googleusercontent.com (doc-14-6c-docs.googleusercontent.com)[172.217.30.193]:443... conectado.\n",
            "Petición HTTP enviada, esperando respuesta... 200 OK\n",
            "Longitud: 5477009 (5,2M) [application/x-zip-compressed]\n",
            "Grabando a: «data»\n",
            "\n",
            "data                100%[===================>]   5,22M  2,49MB/s    en 2,1s    \n",
            "\n",
            "2023-03-02 15:27:17 (2,49 MB/s) - «data» guardado [5477009/5477009]\n",
            "\n",
            "/bin/bash: línea 1: unzip: orden no encontrada\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1osH_xhTCW4Qh7f00VU_UaRK5whEXe8dr' -O data\n",
        "!unzip \"/content/data\" -d \"/content/IMDBAnalyticsData/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FgflsjGscqg"
      },
      "source": [
        "### Importar las librerías necesarias\n",
        "\n",
        "Importe las librerías que le servirán para el procesamiento y visualización de datos. La librería _geopandas_, que sirve para el procesamiento de archivos con información geográfica (_shapefiles_) no está instalada por defecto en el ambiente de google colab. Por esta razón, debe instalarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LyiSFCGUtIaK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: geopandas in /home/yhilmar/.local/lib/python3.10/site-packages (0.12.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /home/yhilmar/.local/lib/python3.10/site-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: shapely>=1.7 in /home/yhilmar/.local/lib/python3.10/site-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: pyproj>=2.6.1.post1 in /home/yhilmar/.local/lib/python3.10/site-packages (from geopandas) (3.4.1)\n",
            "Requirement already satisfied: fiona>=1.8 in /home/yhilmar/.local/lib/python3.10/site-packages (from geopandas) (1.9.1)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3.10/site-packages (from geopandas) (23.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /home/yhilmar/.local/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (22.2.0)\n",
            "Requirement already satisfied: click~=8.0 in /home/yhilmar/.local/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (8.1.3)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2022.12.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /home/yhilmar/.local/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (67.3.0)\n",
            "Requirement already satisfied: munch>=2.3.2 in /home/yhilmar/.local/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/yhilmar/.local/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (1.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/yhilmar/.local/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/lib/python3.10/site-packages (from munch>=2.3.2->fiona>=1.8->geopandas) (1.16.0)\n",
            "Requirement already satisfied: platformdirs in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (2.6.2)\n",
            "Requirement already satisfied: jaraco.text in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (3.11.1)\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (9.0.0)\n",
            "Requirement already satisfied: ordered-set in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (4.1.0)\n",
            "Requirement already satisfied: tomli in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (2.0.1)\n",
            "Requirement already satisfied: validate-pyproject in /usr/lib/python3.10/site-packages (from setuptools->fiona>=1.8->geopandas) (0.12.1)\n",
            "Requirement already satisfied: inflect in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->fiona>=1.8->geopandas) (6.0.2)\n",
            "Requirement already satisfied: autocommand in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->fiona>=1.8->geopandas) (2.2.2)\n",
            "Requirement already satisfied: jaraco.functools in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->fiona>=1.8->geopandas) (3.5.2)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->fiona>=1.8->geopandas) (4.3.0)\n",
            "Requirement already satisfied: fastjsonschema<=3,>=2.16.2 in /usr/lib/python3.10/site-packages (from validate-pyproject->setuptools->fiona>=1.8->geopandas) (2.16.2)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/lib/python3.10/site-packages (from inflect->jaraco.text->setuptools->fiona>=1.8->geopandas) (1.10.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect->jaraco.text->setuptools->fiona>=1.8->geopandas) (4.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0ytEOPM2BqZg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFGheSl0t6az"
      },
      "source": [
        "## **1. Procesamiento básico**\n",
        "\n",
        "En este primer paso, cargará la base de datos (archivo .csv) a un _dataframe_ de pandas y utilizará algunas funciones de la librería que le ayudarán a tener información básica de los datos. De forma resumida, un _dataframe_ de pandas es una estructura de datos bidimensional en la que los datos se organizan en filas y columnas. Es similar a una hoja de cálculo en Excel, donde cada columna representa una variable y cada fila representa una observación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljP8tX71vOIV"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'IMDBAnalyticsData/Data/movie_metadata.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mIMDBAnalyticsData/Data/movie_metadata.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#Cargar el archivo csv al dataframe df\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m) \u001b[39m#Mostrar las primeras 5 filas de la tabla \u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'IMDBAnalyticsData/Data/movie_metadata.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('IMDBAnalyticsData/Data/movie_metadata.csv') #Cargar el archivo csv al dataframe df\n",
        "df.head(5) #Mostrar las primeras 5 filas de la tabla "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ0YtiR9tvAn"
      },
      "outputs": [],
      "source": [
        "df.shape #Tamaño de la tabla (df.shape[0] es el número de filas y df.shape[1] es el número de columnas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yRVGT8_v3kH"
      },
      "outputs": [],
      "source": [
        "df.dtypes #Muestra el tipo de dato que se almacena en cada columna de la tabla"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61wE6sIGwJ0q"
      },
      "source": [
        "Podemos acceder a las filas y columnas del _dataframe_ de las siguientes formas: \n",
        "\n",
        "- Acceder a todas las filas en la columna _director name_\n",
        "```python \n",
        "df[\"director_name\"] \n",
        "df.director_name\n",
        "```\n",
        "La segunda forma solo funciona si el nombre de la columna no tiene espacios\n",
        "\n",
        "- Acceder a unas filas específicas de la columna _director name_\n",
        "```python \n",
        "df.loc[0,\"director_name\"] \n",
        "df.loc[0:10,\"director_name\"]\n",
        "```\n",
        "\n",
        "- Acceder a filas y columnas específicas\n",
        "```python \n",
        "df.loc[0:10,[\"director_name\",\"movie_title\"]]\n",
        "df.iloc[0:10,[0,1]] \n",
        "```\n",
        "El método ```loc``` indexa las columnas por su nombre, mientas que el método ```iloc``` indexa las columnas por su posición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRTYolMAxtBK"
      },
      "outputs": [],
      "source": [
        "df.loc[0:10,[\"director_name\",\"movie_title\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShOvTDy_yDMh"
      },
      "outputs": [],
      "source": [
        "df.iloc[0:10,[0,1]] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfK4TqDMyvmX"
      },
      "source": [
        "## **2. Preparación de datos**\n",
        "\n",
        "Remueva algunas columnas que no son importantes para el análisis que se va a realizar.\n",
        "\n",
        "- _movie_imdb_link_\n",
        "- _num_critic_for_reviews_\n",
        "- _genre_\n",
        "\n",
        "El método ```drop``` permite hacer este proceso. El parámetro ```axis = 1``` se utiliza para que elimine información de las columnas, ```columns``` especifica las columnas a remover, e ```inplace = True``` se utiliza para que la modificación hecha se almacene en la varianle ```df``` sin necesidad de hacer una nueva asignación de variables. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXK7V3ANzFnV"
      },
      "outputs": [],
      "source": [
        "df.drop(axis = 1, columns = [\"movie_imdb_link\",\"num_critic_for_reviews\"],inplace = True)\n",
        "df.head(5) #Mostrar de nuevo las 5 primeras filas para corroborar que se eliminaron las columnas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXRHUbjZ08SP"
      },
      "source": [
        "Ejercicio: Remover la columna faltante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QysBaO300bz"
      },
      "outputs": [],
      "source": [
        "#Código del ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvN0CzB31EQW"
      },
      "source": [
        "Muestre las columnas como una lista para corroborar que las columnas no deseadas se eliminaron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vVvu5Z3z_tK"
      },
      "outputs": [],
      "source": [
        "list(df) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Ra-KHJ1Vb5"
      },
      "source": [
        "Revise de nuevo el tamaño del dataframe. Debe ser diferente al tamaño inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpTsVE660EQj"
      },
      "outputs": [],
      "source": [
        "df.shape "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsjHi_6_2D_M"
      },
      "source": [
        "La columna _title_year_ almacena valores de tipo _float_. Sin embargo, los años se deben manejar como números enteros. Haga esta modificación utilizando el método ```astype```. Este método no permite utilizar el parámetro ```inplace```, por lo que es necesario hacer una re-asignación de la variable _df_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PreV5sJ2wOs"
      },
      "outputs": [],
      "source": [
        "df['title_year'] = df['title_year'].astype(\"Int64\")\n",
        "df['title_year']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kvbY79E1fbB"
      },
      "source": [
        "Cambie el nombre de la columna _gross_ a _movie_income_ utliando el método ```rename```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P23DX-l53AEf"
      },
      "outputs": [],
      "source": [
        "rename_dict = {\"gross\":\"movie_income\", \"language\":\"Language\"}\n",
        "df.rename(columns = rename_dict,inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAhIVvoM39tI"
      },
      "source": [
        "## **3. Análisis de datos**\n",
        "\n",
        "Para el análisis de datos utilizará diferentes tipos de figuras. Empezará con histogramas. Un histograma es una representación gráfica de la distribución de frecuencias de un conjunto de datos numéricos. En un histograma, se dividen los datos en una serie de \"bins\" o \"intervalos\", y se cuenta la frecuencia de observaciones que caen en cada bin. Luego, se grafica la frecuencia de cada bin en el eje vertical y el valor de cada bin en el eje horizontal, lo que permite visualizar la forma y la dispersión de la distribución de los datos.\n",
        "\n",
        "En un histograma, la altura de cada barra representa la frecuencia de los datos que caen en ese bin. Los bins pueden ser de igual ancho (por ejemplo, cada bin puede representar un intervalo de 10 unidades) o de ancho variable (por ejemplo, para representar intervalos de mayor o menor densidad de datos).\n",
        "\n",
        "Visualice la distribución de la columna _duration_ utilizando histogramas. Para esto utilizará el método ```hist```, el parámetro ```bins``` permitirá definir en cuántos intervalos se analizará la frecuencia de repeticiones de eventos, en este caso, duración de las películas. Se almacena la figura en la variable ```ax```, lo que permite agregar información adicional para su interpretación. en esta figura puede observar que la mayoría de películas duran aproximadamente 100 minutos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViWyF0Du4ojS"
      },
      "outputs": [],
      "source": [
        "ax = df[\"duration\"].hist(bins = 20)\n",
        "ax.set_xlabel('Time [mins]')\n",
        "ax.set_ylabel('Counts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNhbznP35kNa"
      },
      "source": [
        "Hará la misma figura utilizando la librería _plotly express_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-3izwbv6By7"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df, x=\"duration\",nbins=40,labels={'duration':'Time [mins] '})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sZek9dm7Elz"
      },
      "source": [
        "Ejercicio: Cree un histograma para ver la distribución de la columna _imdb_score_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esfGiaJl7mHu"
      },
      "outputs": [],
      "source": [
        "#Código del ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px3rt5kjA9Hw"
      },
      "source": [
        "Puede hacer consultas con respecto a alguna variable. Por ejemplo, filtre las película que tengan un _imdb_score_ menor que 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJmEvxZyBOkC"
      },
      "outputs": [],
      "source": [
        "df['imdb_score'] < 4\n",
        "#df.imdb_score < 4 #Esta línea hace lo mismo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cepLj08gBbqH"
      },
      "source": [
        "El resultado es un arreglo unidimensional de pandas de tipo _series_ (similar a un _dataframe_ pero con una sola columna) que va a tomar el valor ```True``` en las filas en las que la condición se cumple y ````False``` en las demás filas. Este nuevo arreglo se puede almacenar en una nueva variable o se puede utilizar para indexar el _dataframe_. En este caso, creará un nuevo _dataframe_ con nombre _df_low_score_ que tendrá todas las columnas de _df_ pero únicamente las filas que cumplen con la condición.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFkAd35NCOkp"
      },
      "outputs": [],
      "source": [
        "index = df['imdb_score'] < 4\n",
        "df_low_score = df[index]\n",
        "df_low_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyw4-UNCcnD"
      },
      "outputs": [],
      "source": [
        "#esta celda es una forma diferente de hacer lo mismo\n",
        "df_low_score = df[df['imdb_score'] < 4]\n",
        "df_low_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OjQ-6TxCayT"
      },
      "source": [
        "Revise que en verdad las películas en este nuevo _dataframe_ tengan un _imdb_score_ menor a 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0qpi5tzDkDF"
      },
      "outputs": [],
      "source": [
        "df_low_score.loc[:,['movie_title','imdb_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZTFEM9JEWou"
      },
      "source": [
        "Ejercicio: Revise la distribución de la columna _imdb_score_ de las películas producidas en USA utilizando histogramas. Si es necesario, cree _dataframes_ que le ayuden a resolver la tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9Q-4LJhE1Z5"
      },
      "outputs": [],
      "source": [
        "#Código del ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahEVmuRV08Im"
      },
      "source": [
        "El método ```groupby``` se usa para agrupar filas de un dataframe según los valores de una o varias columnas, y luego aplicar una o varias funciones de agregación a cada grupo. En otras palabras, el método ```groupby``` permite crear subconjuntos de datos de un dataframe basados en los valores de una o varias columnas, y luego realizar cálculos estadísticos sobre cada uno de estos subconjuntos.\n",
        "\n",
        "Por ejemplo, si quiere saber qué años tienen el mayor y menor número de películas, podemos hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2xIPl671wpy"
      },
      "outputs": [],
      "source": [
        "count_per_year = df.groupby('title_year').size()\n",
        "print(count_per_year)\n",
        "print(f\"El año con mayor cantidad de películas producidas fue {count_per_year.idxmax()} con {count_per_year.max()} películas\")\n",
        "print(f\"El año con menor cantidad de películas producidas fue {count_per_year.idxmin()} con {count_per_year.min()} películas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UC81P585mux"
      },
      "source": [
        "El método ```size``` aplicado a una agrupación de filas creada con ```groupby``` retorna, en un arreglo de tipo ```series```, el número de elementos pertenecientes a cada uno de los grupos que se creó. En este caso particular, el número de películas producidas en cada año. En este arreglo, el índice corresponde a la variable en la cuál se creó el grupo (en este caso el año). \n",
        "\n",
        "El método ```max``` retorna el número más grande en el arreglo mientras que el método ```idxmax``` retorna el índice en el cuál se encuentra ese número.\n",
        "\n",
        "Puede crear una gráfica de barras en la que se muestre la cantidad de películas producidas cada año de la siguiente forma\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESDc1nM_7jQA"
      },
      "outputs": [],
      "source": [
        "ax = count_per_year.plot.bar(figsize = (18,10))\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('# of movies')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-FZ-GcB8BTR"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(x = count_per_year.index, y = count_per_year, labels={'y':'# of movies'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRbTBrC9bAI"
      },
      "source": [
        "Ejercicio: ¿En qué año se tiene el mayor y menor promedio de _imdb_score_?\n",
        "\n",
        "Haga una gráfica de barras para mirar los promedios por año. Tip: El método ```mean()``` permite calcular promedios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMeEDLQA9wSp"
      },
      "source": [
        "Quiere ahora saber en qué año se ha gastado más y en qué año se ha gastado menos presupuesto en películas.\n",
        "\n",
        "Para esto, podemos hacer también una gráfica de líneas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJOWWAHO-COa"
      },
      "outputs": [],
      "source": [
        "df_budget_year = df.groupby('title_year')['budget'].sum()\n",
        "print(f\"Se gastó más presupuesto en el año {df_budget_year.idxmax()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVzSP0sT-ZyF"
      },
      "outputs": [],
      "source": [
        "ax = df_budget_year.plot()\n",
        "ax.set_xlabel(\"Year\")\n",
        "ax.set_ylabel(\"Budget\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3QuNf_u-wDU"
      },
      "source": [
        "Se puede entender mejor la gráfica si mostramos el presupuesto en millones de dólares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFSKU76t_pbo"
      },
      "outputs": [],
      "source": [
        "df_budget_year = df_budget_year / 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS-s-Ds5-0q-"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(x = df_budget_year.index, y = df_budget_year, labels={'y':'Budget (millions)'})\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuBoIfSnASuh"
      },
      "source": [
        "Ahora quiere saber si hay una relación entre  en _imdb_score_ de una película con su _movie_income_. Para esto, vamos a calcular la correlación entre las dos variables. \n",
        "\n",
        "La correlación es una medida estadística que describe la relación entre dos variables. En otras palabras, indica cómo se mueven o cambian juntas dos variables en relación a sus medias. Esta medida puede tomar valores entre -1 y 1. Un coeficiente de correlación de 1 indica una correlación positiva perfecta, lo que significa que a medida que aumenta una variable, también lo hace la otra en la misma proporción. Por otro lado, un coeficiente de correlación de -1 indica una correlación negativa perfecta, lo que significa que a medida que aumenta una variable, la otra disminuye en la misma proporción. Un coeficiente de correlación de 0 indica que no hay relación entre las dos variables.\n",
        "\n",
        "La correlación la podemos analizar de forma visual o de forma cuantitativa.\n",
        "\n",
        "Primero, calcule la correlación entre las dos variables, para esto, debe eliminar las filas con datos faltantes en estas variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVdT8hXE_hSD"
      },
      "outputs": [],
      "source": [
        "df_corr = df.loc[:,['budget','imdb_score']] #Dataframe con las variables a analizar\n",
        "df_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db8jBFcNEDOR"
      },
      "outputs": [],
      "source": [
        "df_corr.dropna(inplace = True)\n",
        "df_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMWQNOC7ED1T"
      },
      "source": [
        "El método ```dropna``` remueve las filas con valores faltantes, almacenados como ```nan``` en el _dataframe_. El parámetro ```inplace = True``` asegura que los cambios se almacenen en la variable _df_corr_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7rAiuddEkxj"
      },
      "source": [
        "El método ```plot.scatter``` grafica relaciones entre 2 variables. En este caso, en el eje x tenemos la variable _budget_ y en el eje y la variable _imdb_score_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuowpfNiEaTe"
      },
      "outputs": [],
      "source": [
        "ax = df_corr.plot.scatter('budget','imdb_score',figsize = (10,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Vy8TfQE843"
      },
      "source": [
        "Los valores atípico en la variable _budget_ dificultan la interpretación de la gráfica. Vamos a eliminar las filas del _dataframe_ con valores mayores a 2e9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Ji4YP2H6FVF1"
      },
      "outputs": [],
      "source": [
        "df_corr = df_corr[df_corr['budget']<2000000000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2xPtkF1FeKS"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(df_corr, x=\"budget\", y=\"imdb_score\", labels = {'budget': 'Budget per movie', 'imdb_score':'IMDB score'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrdDgRm_GgBp"
      },
      "source": [
        "Puede ver que hay una relación entre las dos variables. Si quiere cuantificar esta relación puede utilizar la correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIgsUaRrHbNg"
      },
      "outputs": [],
      "source": [
        "corr_mat = df_corr.corr()\n",
        "print(corr_mat)\n",
        "print(f\"La correlación entre las variables budget e IMDB score es de {corr_mat.iloc[0,1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2XKT-EZIMCm"
      },
      "source": [
        "## **4. Análisis geoespacial**\n",
        "\n",
        "En este punto llevará los análisis que se han hecho a gráficas que nos puedan dar información acerca de los países donde se produjeron las películas. para esto utilizará la librería ```geopandas```\n",
        "\n",
        "La función ```gpd.read_file``` carga un _dataframe_ de ```geopandas```. En este caso está seleccionando las columnas con la información relevante para las figuras y les está cambiando el nombre. La columna _geometry_ tiene la información de los polígonos que conforman cada país."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXslZDX3In6X"
      },
      "outputs": [],
      "source": [
        "shpfile = 'IMDBAnalyticsData/Data/Map/ne_10m_admin_0_countries.shp'\n",
        "geo_df = gpd.read_file(shpfile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
        "geo_df.columns = ['country', 'country_code', 'geometry']\n",
        "geo_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYHMMZzfJ9j6"
      },
      "source": [
        "En este caso, puede remover la fila correspondiente a la antártica dado que ocupa mucho espacio en el mapa y no es relevante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD6gnIDkJ11Q"
      },
      "outputs": [],
      "source": [
        "geo_df = geo_df.drop(geo_df.loc[geo_df['country'] == 'Antarctica'].index)\n",
        "geo_df.plot(figsize=(20, 20), edgecolor='white', linewidth=1, color='lightblue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yi2fXV8KRRY"
      },
      "source": [
        "Puede observar la lista de países que se encuentran en el mapa, que seguramente son más de los países de los que se tiene registro de películas (eso por ahora es irrelevante)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah1QnWF3KQTU"
      },
      "outputs": [],
      "source": [
        "geo_df['country']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaVZDrUlKfwg"
      },
      "source": [
        "Ahora, va a obtener información que se pueda graficar en el mapa. Por ejemplo, el número de películas producidas en cada país."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9FUUngdKffP"
      },
      "outputs": [],
      "source": [
        "df_mbc = df.groupby('country').size().to_frame('# of movies')\n",
        "df_mbc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUcVYnugK1ww"
      },
      "source": [
        "Ahora, va a combinar la información de ambas tablas. Básicamente, debe adjuntar la información contenida en el _shapefile_ a cada uno de los países para los que se tiene registro de películas. Para esto va a utilizar la función ```pd.merge```.\n",
        "\n",
        "La función ```pd.merge``` se utiliza para combinar dos o más dataframes en función de una o varias columnas en común, similar a un join en SQL. El resultado de la operación es un nuevo dataframe que contiene todas las filas y columnas de los dataframes originales que cumplen con las condiciones de combinación especificadas.\n",
        "\n",
        "La función pd.merge toma como entrada dos dataframes, junto con los argumentos que indican las columnas en común en las que se desea fusionar los dataframes. Existen varios tipos de combinaciones que se pueden especificar mediante el argumento \"how\", como \"inner\" (intersección), \"outer\" (unión), \"left\" (izquierda) y \"right\" (derecha).\n",
        "\n",
        "Cuando se utiliza la función ```pd.merge```, se puede especificar un conjunto de columnas en las que se debe basar la combinación, utilizando el argumento \"on\". También se pueden especificar diferentes nombres de columnas para cada dataframe, utilizando los argumentos ```left_on``` y ```right_on```. En caso de que las columnas en común tengan nombres diferentes en los dataframes originales, se pueden utilizar los argumentos ```left_index``` y ```right_index``` para especificar que las combinaciones se realicen en los índices en lugar de en las columnas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBXl53MfK1ct"
      },
      "outputs": [],
      "source": [
        "df_mbc_shp = pd.merge(left=geo_df, right=df_mbc, how='left', left_on='country', right_on='country')\n",
        "df_mbc_shp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-KBsI1ALkv-"
      },
      "source": [
        "Por último, grafique en el mapa la cantidad de películas producidas en cada país.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGmddlhtNEBn"
      },
      "outputs": [],
      "source": [
        "fig = px.choropleth_mapbox(df_mbc_shp,\n",
        "                           geojson=df_mbc_shp.geometry,\n",
        "                           locations=df_mbc_shp.index,\n",
        "                           color=\"# of movies\",\n",
        "                           mapbox_style=\"open-street-map\",\n",
        "                           opacity = 0.5,\n",
        "                           zoom=8.5)\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOp1a4T1ilk+GWdW7SQ/kvP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
